{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saponjyan/CV/blob/main/Bipedalwalker_V2_PPO2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyyN-2qyK_T2"
      },
      "source": [
        "\n",
        "# Deep Learning Labs S01 E05: BiPedalwalker-V2\n",
        "\n",
        "This colab will allow you to train, evaluate and visulize your results. As Google colab don't support env.render() we will use a work around where we \"fake\" a display, record a video and then display it.\n",
        "\n",
        "Notebook will run with classic **CPU** enviorment as well as **GPU** & **TPU**\n",
        "\n",
        "> To run it all select `runtime` in menu and choose `run all`\n",
        "\n",
        "![Nextgrid Deep learning labs](https://nextgrid.ai/wp-content/uploads/2019/12/Deck-wallpaper-logo-scaled.jpg)\n",
        "\n",
        "### Stable Baselines OpenAI Gym BiPedalwalker-V2\n",
        "\n",
        "Notebook by [nextgrid.ai](https://nextgrid.ai) for [Deep learning labs](https://nextgrid.ai/deep-learning-labs/) #5.\n",
        "\n",
        "\n",
        "Documentation for stabile-baselines available at: [https://stable-baselines.readthedocs.io/](https://stable-baselines.readthedocs.io/)\n",
        "\n",
        "\n",
        "notebook authored by M.   \n",
        "[linkedin](https://www.linkedin.com/in/imathias) / [twitter](https://twitter.com/mathiiias123)   \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Новый раздел"
      ],
      "metadata": {
        "id": "P9Oi5aT1ZMUJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22TBe2qeFlyr"
      },
      "source": [
        "## Install system wide packages\n",
        "Install linux server packages using `apt-get` and Python packages using `pip`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWskDE2c9WoN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a25a3c48-eed8-4f22-d8e6-b04ce245abb7"
      },
      "source": [
        "!apt-get install swig cmake libopenmpi-dev zlib1g-dev xvfb x11-utils ffmpeg -qq #remove -qq for full output\n",
        "!pip install stable-baselines[mpi] box2d box2d-kengz pyvirtualdisplay pyglet==1.3.1 --quiet #remove --quiet for full output\n",
        "# Stable Baselines only supports tensorflow 1.x for now\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for box2d-kengz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for mpi4py (pyproject.toml) ... \u001b[?25l\u001b[?25hcanceled\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 169, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 242, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 417, in run\n",
            "    _, build_failures = build(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 320, in build\n",
            "    wheel_file = _build_one(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 194, in _build_one\n",
            "    wheel_path = _build_one_inside_env(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/wheel_builder.py\", line 234, in _build_one_inside_env\n",
            "    wheel_path = build_wheel_pep517(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/build/wheel.py\", line 30, in build_wheel_pep517\n",
            "    wheel_name = backend.build_wheel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/misc.py\", line 665, in build_wheel\n",
            "    return super().build_wheel(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 209, in build_wheel\n",
            "    return self._call_hook('build_wheel', {\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pyproject_hooks/_impl.py\", line 311, in _call_hook\n",
            "    self._subprocess_runner(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 252, in runner\n",
            "    call_subprocess(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/subprocess.py\", line 166, in call_subprocess\n",
            "    line: str = proc.stdout.readline()\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 79, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 206, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1524, in critical\n",
            "    self._log(CRITICAL, msg, args, **kwargs)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1624, in _log\n",
            "    self.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1634, in handle\n",
            "    self.callHandlers(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1696, in callHandlers\n",
            "    hdlr.handle(record)\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 968, in handle\n",
            "    self.emit(record)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
            "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1672, in print\n",
            "    renderables = self._collect_renderables(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1551, in _collect_renderables\n",
            "    check_text()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/console.py\", line 1529, in check_text\n",
            "    append(sep_text.join(text))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/rich/text.py\", line 748, in join\n",
            "    def iter_text() -> Iterable[\"Text\"]:\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 309, in inner\n",
            "    return cached(*args, **kwds)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 1145, in __getitem__\n",
            "    return self.copy_with(params)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 1148, in copy_with\n",
            "    return _GenericAlias(self.__origin__, params,\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 1019, in __init__\n",
            "    super().__init__(origin, inst=inst, name=name)\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 949, in __init__\n",
            "    self._name = name\n",
            "  File \"/usr/lib/python3.10/typing.py\", line 989, in __setattr__\n",
            "    super().__setattr__(attr, val)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-269e466410a1>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip install stable-baselines[mpi] box2d box2d-kengz pyvirtualdisplay pyglet==1.3.1 --quiet #remove --quiet for full output'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Stable Baselines only supports tensorflow 1.x for now\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensorflow_version'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1.x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_tensorflow_magics.py\u001b[0m in \u001b[0;36m_tensorflow_version\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;31m# pylint: disable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         textwrap.dedent(\n",
            "\u001b[0;31mValueError\u001b[0m: Tensorflow 1 is unsupported in Colab.\n\nYour notebook should be updated to use Tensorflow 2.\nSee the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQL5IxILUblP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtY8FhliLsGm"
      },
      "source": [
        "## Dependencis\n",
        "import dependencis required to run & train our model + record a video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2pToLfvOzCKQ"
      },
      "source": [
        "import gym\n",
        "import imageio\n",
        "import numpy as np\n",
        "import base64\n",
        "import IPython\n",
        "import PIL.Image\n",
        "import pyvirtualdisplay\n",
        "\n",
        "# Video stuff\n",
        "from pathlib import Path\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "from stable_baselines.common.policies import MlpPolicy\n",
        "from stable_baselines.common.vec_env import VecVideoRecorder, SubprocVecEnv, DummyVecEnv\n",
        "from stable_baselines import PPO2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WlaTq_UvGKo-"
      },
      "source": [
        "## Define variables & functions\n",
        "Here we define our variables and also create a couple of functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKA52SBe6JdJ"
      },
      "source": [
        "# set enviorment variables that we will use in our code\n",
        "env_id = 'BipedalWalker-v2'\n",
        "video_folder = '/videos'\n",
        "video_length = 100\n",
        "\n",
        "# set our inital enviorment\n",
        "env = DummyVecEnv([lambda: gym.make(env_id)])\n",
        "obs = env.reset()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBVNrcLawXeB"
      },
      "source": [
        "# Evaluation Function\n",
        "def evaluate(model, num_steps=1000):\n",
        "  \"\"\"\n",
        "  Evaluate a RL agent\n",
        "  :param model: (BaseRLModel object) the RL Agent\n",
        "  :param num_steps: (int) number of timesteps to evaluate it\n",
        "  :return: (float) Mean reward for the last 100 episodes\n",
        "  \"\"\"\n",
        "  episode_rewards = [0.0]\n",
        "  obs = env.reset()\n",
        "  for i in range(num_steps):\n",
        "      # _states are only useful when using LSTM policies\n",
        "      action, _states = model.predict(obs)\n",
        "\n",
        "      obs, reward, done, info = env.step(action)\n",
        "\n",
        "      # Stats\n",
        "      episode_rewards[-1] += reward\n",
        "      if done:\n",
        "          obs = env.reset()\n",
        "          episode_rewards.append(0.0)\n",
        "  # Compute mean reward for the last 100 episodes\n",
        "  mean_100ep_reward = round(np.mean(episode_rewards[-100:]), 1)\n",
        "  print(\"Mean reward:\", mean_100ep_reward, \"Num episodes:\", len(episode_rewards))\n",
        "\n",
        "  return mean_100ep_reward"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAqAATOx79Xt"
      },
      "source": [
        "# Make video\n",
        "# Set up fake display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-qEyqYl86uI"
      },
      "source": [
        "# Record video\n",
        "def record_video(env_id, model, video_length=500, prefix='', video_folder='videos/'):\n",
        "  \"\"\"\n",
        "  :param env_id: (str)\n",
        "  :param model: (RL model)\n",
        "  :param video_length: (int)\n",
        "  :param prefix: (str)\n",
        "  :param video_folder: (str)\n",
        "  \"\"\"\n",
        "  eval_env = DummyVecEnv([lambda: gym.make('BipedalWalker-v2')])\n",
        "  # Start the video at step=0 and record 500 steps\n",
        "  eval_env = VecVideoRecorder(env, video_folder=video_folder,\n",
        "                              record_video_trigger=lambda step: step == 0, video_length=video_length,\n",
        "                              name_prefix=prefix)\n",
        "\n",
        "  obs = eval_env.reset()\n",
        "  for _ in range(video_length):\n",
        "    action, _ = model.predict(obs)\n",
        "    obs, _, _, _ = eval_env.step(action)\n",
        "\n",
        "  # Close the video recorder\n",
        "  eval_env.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0KzI3_n81YH"
      },
      "source": [
        "# Display video\n",
        "def show_videos(video_path='', prefix=''):\n",
        "  html = []\n",
        "  for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "      video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "      html.append('''<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "  ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ID-CT-JiWkEq"
      },
      "source": [
        "# Define & Configure out Reinforcment learning algoritm\n",
        "In this example we are using default PPO2 / Proximal Policy Optimization. Read more about how you define your PPO2 [parameters](https://stable-baselines.readthedocs.io/en/master/modules/ppo2.html#parameters)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQRSdpIa1e2o"
      },
      "source": [
        "# Define the model\n",
        "model = PPO2(MlpPolicy, env, verbose=1) # add & tweak default parameters, messure your output & improve link to parameters above (it will however work with default)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmK85N-4XdK7"
      },
      "source": [
        "## Train model 50k steps & evaluate results\n",
        "Here we train, evaluate, save, record & display video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIedd7Pz9sOs"
      },
      "source": [
        "\n",
        "# Random Agent, before training\n",
        "mean_reward_before_train = evaluate(model, num_steps=10000)\n",
        "\n",
        "# Train model\n",
        "model.learn(total_timesteps=50000)\n",
        "\n",
        "# Save model\n",
        "model.save(\"ppo2-walker-50000\")\n",
        "\n",
        "# Random Agent, after training\n",
        "mean_reward_after_train = evaluate(model, num_steps=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcRLC8Wldwwf"
      },
      "source": [
        "# Record & show video\n",
        "record_video('BipedalWalker-v2', model, video_length=1500, prefix='ppo2-walker-50000')\n",
        "show_videos('videos', prefix='ppo2-walker-50000')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5UoXTZPNdFE"
      },
      "source": [
        "## Train model another 500k steps & evaluate results\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6Kp_p3OXHvi"
      },
      "source": [
        "# Random Agent, before training\n",
        "mean_reward_before_train = evaluate(model, num_steps=10000)\n",
        "\n",
        "# Train model\n",
        "model.learn(total_timesteps=500000)\n",
        "\n",
        "# Save model\n",
        "model.save(\"ppo2-walker-500000\")\n",
        "\n",
        "# Random Agent, after training\n",
        "mean_reward_after_train = evaluate(model, num_steps=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNrCLGTMd1mg"
      },
      "source": [
        "# Record & show video\n",
        "record_video('BipedalWalker-v2', model, video_length=1500, prefix='ppo2-walker-500000')\n",
        "show_videos('videos', prefix='ppo2-walker-500000')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}